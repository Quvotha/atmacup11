{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NO = 7\n",
    "SEED = 1\n",
    "N_SPLITS = 5\n",
    "TARGET = 'sorting_date'\n",
    "GROUP = 'art_series_id'\n",
    "REGRESSION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((TARGET, REGRESSION) in (('target', True), ('target', False), ('sorting_date', True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import gc\n",
    "import glob\n",
    "import json\n",
    "from logging import getLogger, StreamHandler, FileHandler, DEBUG, Formatter\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, cohen_kappa_score\n",
    "\n",
    "SCRIPTS_DIR = os.path.join('..', 'scripts')\n",
    "assert(os.path.isdir(SCRIPTS_DIR))\n",
    "if SCRIPTS_DIR not in sys.path: sys.path.append(SCRIPTS_DIR)\n",
    "\n",
    "from cross_validation import load_cv_object_ids\n",
    "from dataset import load_csvfiles, load_photofile\n",
    "from folder import experiment_dir_of\n",
    "from target import soring_date2target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.5f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = experiment_dir_of(EXP_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\scripts\\\\..\\\\experiments\\\\exp007'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Refference\n",
    "https://docs.python.org/ja/3/howto/logging-cookbook.html\n",
    "'''\n",
    "logger.setLevel(DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "fh = FileHandler(os.path.join(output_dir, 'log.log'))\n",
    "fh.setLevel(DEBUG)\n",
    "# create console handler with a higher log level\n",
    "ch = StreamHandler()\n",
    "ch.setLevel(DEBUG)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "len(logger.handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 18:24:45,580 - __main__ - INFO - Experiment no: 7\n",
      "2021-07-17 18:24:45,583 - __main__ - INFO - CV: StratifiedGroupKFold\n",
      "2021-07-17 18:24:45,585 - __main__ - INFO - SEED: 1\n",
      "2021-07-17 18:24:45,586 - __main__ - INFO - REGRESSION: True\n",
      "2021-07-17 18:24:45,587 - __main__ - INFO - TARGET: sorting_date\n"
     ]
    }
   ],
   "source": [
    "logger.info('Experiment no: {}'.format(EXP_NO))\n",
    "logger.info('CV: StratifiedGroupKFold')\n",
    "logger.info('SEED: {}'.format(SEED))\n",
    "logger.info('REGRESSION: {}'.format(REGRESSION))\n",
    "logger.info('TARGET: {}'.format(TARGET))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINCE = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 18:24:45,629 - __main__ - DEBUG - Start loading csv files (0.020 seconds passed)\n",
      "2021-07-17 18:24:45,661 - __main__ - DEBUG - Complete loading csv files (0.052 seconds passed)\n"
     ]
    }
   ],
   "source": [
    "logger.debug('Start loading csv files ({:.3f} seconds passed)'.format(time.time() - SINCE))\n",
    "train, test, materials, techniques, sample_submission = load_csvfiles()\n",
    "logger.debug('Complete loading csv files ({:.3f} seconds passed)'.format(time.time() - SINCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>sorting_date</th>\n",
       "      <th>art_series_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002bff09b09998d0be65</td>\n",
       "      <td>1631</td>\n",
       "      <td>509357f67692a6a45626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00309fb1ef05416f9c1f</td>\n",
       "      <td>1900</td>\n",
       "      <td>7987b47bbe5dc3039179</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>003a1562e97f79ba96dc</td>\n",
       "      <td>1834</td>\n",
       "      <td>ded7c3c9636708e5b14c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004890880e8e7431147b</td>\n",
       "      <td>1743</td>\n",
       "      <td>582ac2d7f0cef195b605</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00718c32602425f504c1</td>\n",
       "      <td>1885</td>\n",
       "      <td>64c907f0c08dce4fb8e8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>ffa3259fff8e6f3818a1</td>\n",
       "      <td>1850</td>\n",
       "      <td>b187c294b0550acf049a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>ffd4d361756587883e48</td>\n",
       "      <td>1670</td>\n",
       "      <td>ad49a044770a48f860a6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3934</th>\n",
       "      <td>ffd794b7b311b7b7fd92</td>\n",
       "      <td>1789</td>\n",
       "      <td>f030a01b480b18a27be2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3935</th>\n",
       "      <td>ffe49bba69d06446de7e</td>\n",
       "      <td>1805</td>\n",
       "      <td>f5287bc84a05aada1d17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>ffe77db10be3400bed53</td>\n",
       "      <td>1700</td>\n",
       "      <td>60dec6e091cdd973e617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 object_id  sorting_date         art_series_id  target\n",
       "0     002bff09b09998d0be65          1631  509357f67692a6a45626       1\n",
       "1     00309fb1ef05416f9c1f          1900  7987b47bbe5dc3039179       3\n",
       "2     003a1562e97f79ba96dc          1834  ded7c3c9636708e5b14c       3\n",
       "3     004890880e8e7431147b          1743  582ac2d7f0cef195b605       2\n",
       "4     00718c32602425f504c1          1885  64c907f0c08dce4fb8e8       3\n",
       "...                    ...           ...                   ...     ...\n",
       "3932  ffa3259fff8e6f3818a1          1850  b187c294b0550acf049a       3\n",
       "3933  ffd4d361756587883e48          1670  ad49a044770a48f860a6       1\n",
       "3934  ffd794b7b311b7b7fd92          1789  f030a01b480b18a27be2       2\n",
       "3935  ffe49bba69d06446de7e          1805  f5287bc84a05aada1d17       3\n",
       "3936  ffe77db10be3400bed53          1700  60dec6e091cdd973e617       1\n",
       "\n",
       "[3937 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009e50b94be36ccad39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000bd5e82eb22f199f44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0015f44de1854f617516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00388a678879ba1efa27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005e1e7c6496902d23f3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>ffbe65ad399b632dcbd0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>ffd7b2d646c0320c311a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>ffdb93ede17d4501e530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>ffe111402004b0ed46b4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>fffdb3c248a7dcd3cccf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5919 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 object_id\n",
       "0     0009e50b94be36ccad39\n",
       "1     000bd5e82eb22f199f44\n",
       "2     0015f44de1854f617516\n",
       "3     00388a678879ba1efa27\n",
       "4     005e1e7c6496902d23f3\n",
       "...                    ...\n",
       "5914  ffbe65ad399b632dcbd0\n",
       "5915  ffd7b2d646c0320c311a\n",
       "5916  ffdb93ede17d4501e530\n",
       "5917  ffe111402004b0ed46b4\n",
       "5918  fffdb3c248a7dcd3cccf\n",
       "\n",
       "[5919 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract hog features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_train_hog_feature = os.path.join('exp006', 'train_hog_features.pkl')\n",
    "if os.path.isfile(path_train_hog_feature):\n",
    "    with open(path_train_hog_feature, 'rb') as f:\n",
    "        train_hog_features = pickle.load(f)\n",
    "else:\n",
    "    train_hog_features = {object_id: hog(load_photofile(object_id)) for object_id in train['object_id']}\n",
    "    with open(path_train_hog_feature, 'wb') as f:\n",
    "        pickle.dump(train_hog_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_test_hog_feature = os.path.join('exp006', 'test_hog_features.pkl') \n",
    "if os.path.isfile(path_test_hog_feature):\n",
    "    with open(path_test_hog_feature, 'rb') as f:\n",
    "        X_test = pickle.load(f)\n",
    "else:\n",
    "    X_test = np.array([hog(load_photofile(object_id)) for object_id in test['object_id']])\n",
    "    with open(path_test_hog_feature, 'wb') as f:\n",
    "        pickle.dump(X_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('object_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 18:24:50,243 - __main__ - DEBUG - Start fold 1 (4.633 seconds passed)\n",
      "2021-07-17 18:24:50,975 - __main__ - DEBUG - Start training model (5.365 seconds passed)\n",
      "2021-07-17 18:28:08,342 - __main__ - DEBUG - Complete training (202.733 seconds passed)\n",
      "2021-07-17 18:53:38,044 - __main__ - DEBUG - Save training fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold1_training.csv (1732.435 seconds passed)\n",
      "2021-07-17 18:53:38,065 - __main__ - DEBUG - Save validation fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold1_validation.csv (1732.456 seconds passed)\n",
      "2021-07-17 18:53:38,099 - __main__ - DEBUG - Save test result ..\\scripts\\..\\experiments\\exp007\\cv_fold1_test.csv (1732.490 seconds passed)\n",
      "2021-07-17 18:53:40,015 - __main__ - DEBUG - Save model ..\\scripts\\..\\experiments\\exp007\\cv_fold1_model.pkl (1734.406 seconds passed)\n",
      "2021-07-17 18:53:40,508 - __main__ - DEBUG - Complete fold 1 (1734.899 seconds passed)\n",
      "2021-07-17 18:53:40,509 - __main__ - DEBUG - Start fold 2 (1734.900 seconds passed)\n",
      "2021-07-17 18:53:47,523 - __main__ - DEBUG - Start training model (1741.913 seconds passed)\n",
      "2021-07-17 18:57:03,074 - __main__ - DEBUG - Complete training (1937.464 seconds passed)\n",
      "2021-07-17 19:21:44,091 - __main__ - DEBUG - Save training fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold2_training.csv (3418.482 seconds passed)\n",
      "2021-07-17 19:21:44,104 - __main__ - DEBUG - Save validation fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold2_validation.csv (3418.495 seconds passed)\n",
      "2021-07-17 19:21:44,129 - __main__ - DEBUG - Save test result ..\\scripts\\..\\experiments\\exp007\\cv_fold2_test.csv (3418.520 seconds passed)\n",
      "2021-07-17 19:21:46,007 - __main__ - DEBUG - Save model ..\\scripts\\..\\experiments\\exp007\\cv_fold2_model.pkl (3420.398 seconds passed)\n",
      "2021-07-17 19:21:46,495 - __main__ - DEBUG - Complete fold 2 (3420.886 seconds passed)\n",
      "2021-07-17 19:21:46,496 - __main__ - DEBUG - Start fold 3 (3420.887 seconds passed)\n",
      "2021-07-17 19:21:49,684 - __main__ - DEBUG - Start training model (3424.075 seconds passed)\n",
      "2021-07-17 19:24:19,622 - __main__ - DEBUG - Complete training (3574.013 seconds passed)\n",
      "2021-07-17 19:52:10,176 - __main__ - DEBUG - Save training fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold3_training.csv (5244.566 seconds passed)\n",
      "2021-07-17 19:52:10,199 - __main__ - DEBUG - Save validation fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold3_validation.csv (5244.590 seconds passed)\n",
      "2021-07-17 19:52:10,230 - __main__ - DEBUG - Save test result ..\\scripts\\..\\experiments\\exp007\\cv_fold3_test.csv (5244.621 seconds passed)\n",
      "2021-07-17 19:52:11,884 - __main__ - DEBUG - Save model ..\\scripts\\..\\experiments\\exp007\\cv_fold3_model.pkl (5246.275 seconds passed)\n",
      "2021-07-17 19:52:12,404 - __main__ - DEBUG - Complete fold 3 (5246.794 seconds passed)\n",
      "2021-07-17 19:52:12,406 - __main__ - DEBUG - Start fold 4 (5246.796 seconds passed)\n",
      "2021-07-17 19:52:19,395 - __main__ - DEBUG - Start training model (5253.786 seconds passed)\n",
      "2021-07-17 19:55:40,261 - __main__ - DEBUG - Complete training (5454.652 seconds passed)\n",
      "2021-07-17 20:47:52,947 - __main__ - DEBUG - Save training fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold4_training.csv (8587.334 seconds passed)\n",
      "2021-07-17 20:47:53,011 - __main__ - DEBUG - Save validation fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold4_validation.csv (8587.402 seconds passed)\n",
      "2021-07-17 20:47:53,053 - __main__ - DEBUG - Save test result ..\\scripts\\..\\experiments\\exp007\\cv_fold4_test.csv (8587.444 seconds passed)\n",
      "2021-07-17 20:47:55,937 - __main__ - DEBUG - Save model ..\\scripts\\..\\experiments\\exp007\\cv_fold4_model.pkl (8590.328 seconds passed)\n",
      "2021-07-17 20:47:56,910 - __main__ - DEBUG - Complete fold 4 (8591.301 seconds passed)\n",
      "2021-07-17 20:47:56,913 - __main__ - DEBUG - Start fold 5 (8591.304 seconds passed)\n",
      "2021-07-17 20:48:03,778 - __main__ - DEBUG - Start training model (8598.169 seconds passed)\n",
      "2021-07-17 20:57:06,671 - __main__ - DEBUG - Complete training (9141.053 seconds passed)\n",
      "2021-07-17 21:33:30,934 - __main__ - DEBUG - Save training fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold5_training.csv (11325.325 seconds passed)\n",
      "2021-07-17 21:33:30,965 - __main__ - DEBUG - Save validation fold to ..\\scripts\\..\\experiments\\exp007\\cv_fold5_validation.csv (11325.356 seconds passed)\n",
      "2021-07-17 21:33:30,996 - __main__ - DEBUG - Save test result ..\\scripts\\..\\experiments\\exp007\\cv_fold5_test.csv (11325.387 seconds passed)\n",
      "2021-07-17 21:33:32,826 - __main__ - DEBUG - Save model ..\\scripts\\..\\experiments\\exp007\\cv_fold5_model.pkl (11327.217 seconds passed)\n",
      "2021-07-17 21:33:33,976 - __main__ - DEBUG - Complete fold 5 (11328.367 seconds passed)\n"
     ]
    }
   ],
   "source": [
    "fold_object_ids = load_cv_object_ids()\n",
    "for i, (train_object_ids, valid_object_ids) in enumerate(zip(fold_object_ids[0], fold_object_ids[1])):\n",
    "    assert(set(train_object_ids) & set(valid_object_ids) == set())\n",
    "    num_fold = i + 1\n",
    "    logger.debug('Start fold {} ({:.3f} seconds passed)'.format(num_fold, time.time() - SINCE))\n",
    "    # Separate dataset into training/validation fold\n",
    "    X_train = np.array([train_hog_features[object_id] for object_id in train_object_ids])\n",
    "    y_train = train.loc[train_object_ids, TARGET].values\n",
    "    X_valid = np.array([train_hog_features[object_id] for object_id in valid_object_ids])\n",
    "    y_valid = train.loc[valid_object_ids, TARGET].values\n",
    "    \n",
    "    # Training\n",
    "    logger.debug('Start training model ({:.3f} seconds passed)'.format(time.time() - SINCE))\n",
    "    ## train estimator\n",
    "    estimator = SVR(C=10.0)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    logger.debug('Complete training ({:.3f} seconds passed)'.format(time.time() - SINCE))\n",
    "    \n",
    "    # Save model and prediction\n",
    "    ## Prediction\n",
    "    if REGRESSION:\n",
    "        pred_train = pd.DataFrame(data=estimator.predict(X_train), columns=['pred'])\n",
    "        pred_valid = pd.DataFrame(data=estimator.predict(X_valid), columns=['pred'])\n",
    "        pred_test = pd.DataFrame(data=estimator.predict(X_test), columns=['pred'])\n",
    "    else:\n",
    "        try:\n",
    "            pred_train = pd.DataFrame(data=estimator.predict_proba(X_train),\n",
    "                                      columns=estimator.classes_)\n",
    "            pred_valid = pd.DataFrame(data=estimator.predict_proba(X_valid),\n",
    "                                      columns=estimator.classes_)\n",
    "            pred_test = pd.DataFrame(data=estimator.predict_proba(X_test),\n",
    "                                     columns=estimator.classes_)\n",
    "        except AttributeError:\n",
    "            pred_train = pd.DataFrame(data=estimator.decision_function(X_train),\n",
    "                                      columns=estimator.classes_)\n",
    "            pred_valid = pd.DataFrame(data=estimator.decision_function(X_valid),\n",
    "                                      columns=estimator.classes_)\n",
    "            pred_test = pd.DataFrame(data=estimator.decision_function(X_test),\n",
    "                                     columns=estimator.classes_)\n",
    "    ## Training set\n",
    "    pred_train['object_id'] = train_object_ids\n",
    "    filepath_fold_train = os.path.join(output_dir, f'cv_fold{num_fold}_training.csv')\n",
    "    pred_train.to_csv(filepath_fold_train, index=False)\n",
    "    logger.debug('Save training fold to {} ({:.3f} seconds passed)' \\\n",
    "                .format(filepath_fold_train, time.time() - SINCE))\n",
    "    ## Validation set\n",
    "    pred_valid['object_id'] = valid_object_ids\n",
    "    filepath_fold_valid = os.path.join(output_dir, f'cv_fold{num_fold}_validation.csv')\n",
    "    pred_valid.to_csv(filepath_fold_valid, index=False)\n",
    "    logger.debug('Save validation fold to {} ({:.3f} seconds passed)' \\\n",
    "                .format(filepath_fold_valid, time.time() - SINCE))\n",
    "    ## Test set\n",
    "    pred_test['object_id'] = test['object_id'].values\n",
    "    filepath_fold_test = os.path.join(output_dir, f'cv_fold{num_fold}_test.csv')\n",
    "    pred_test.to_csv(filepath_fold_test, index=False)\n",
    "    logger.debug('Save test result {} ({:.3f} seconds passed)' \\\n",
    "                 .format(filepath_fold_test, time.time() - SINCE))\n",
    "    ## Model\n",
    "    filepath_fold_model = os.path.join(output_dir, f'cv_fold{num_fold}_model.pkl')\n",
    "    with open(filepath_fold_model, 'wb') as f:\n",
    "        pickle.dump(estimator, f)\n",
    "    logger.debug('Save model {} ({:.3f} seconds passed)'.format(filepath_fold_model, time.time() - SINCE))\n",
    "    \n",
    "    # Save memory\n",
    "    del (estimator, X_train, X_valid, y_train, y_valid, pred_train, pred_valid, pred_test)\n",
    "    gc.collect()\n",
    "\n",
    "    logger.debug('Complete fold {} ({:.3f} seconds passed)'.format(num_fold, time.time() - SINCE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = partial(mean_squared_error, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qwk = partial(cohen_kappa_score, labels=np.sort(train['target'].unique()), weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def predict(proba_0: float, proba_1: float, proba_2: float, proba_3: float) -> int:\n",
    "    return np.argmax((proba_0, proba_1, proba_2, proba_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 22:56:31,484 - __main__ - DEBUG - Evaluate cv result (training set) Fold 1\n",
      "2021-07-17 22:56:31,517 - __main__ - DEBUG - Loss: 0.927293163710899\n",
      "2021-07-17 22:56:31,518 - __main__ - DEBUG - Evaluate cv result (training set) Fold 2\n",
      "2021-07-17 22:56:31,539 - __main__ - DEBUG - Loss: 0.9233516654054185\n",
      "2021-07-17 22:56:31,539 - __main__ - DEBUG - Evaluate cv result (training set) Fold 3\n",
      "2021-07-17 22:56:31,554 - __main__ - DEBUG - Loss: 0.9122615650198098\n",
      "2021-07-17 22:56:31,554 - __main__ - DEBUG - Evaluate cv result (training set) Fold 4\n",
      "2021-07-17 22:56:31,583 - __main__ - DEBUG - Loss: 0.9357534492410368\n",
      "2021-07-17 22:56:31,583 - __main__ - DEBUG - Evaluate cv result (training set) Fold 5\n",
      "2021-07-17 22:56:31,608 - __main__ - DEBUG - Loss: 0.9278275920992741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0   60  309    0]\n",
      " [   0   37  671    6]\n",
      " [   0    2 1181   23]\n",
      " [   0    1  680  170]]\n",
      "[[   0   76  307    1]\n",
      " [   0   56  653    6]\n",
      " [   0    4 1188   23]\n",
      " [   0    2  670  175]]\n",
      "[[   0   89  287    2]\n",
      " [   0   75  621   11]\n",
      " [   0    6 1156   39]\n",
      " [   0    3  642  216]]\n",
      "[[   0   50  331    1]\n",
      " [   0   31  676    6]\n",
      " [   0    1 1221   15]\n",
      " [   0    1  657  162]]\n",
      "[[   0   80  305    2]\n",
      " [   0   62  668    5]\n",
      " [   0    3 1164   18]\n",
      " [   0    2  675  164]]\n"
     ]
    }
   ],
   "source": [
    "pred_train_dfs = []\n",
    "for i in range(N_SPLITS):\n",
    "    num_fold = i + 1\n",
    "    logger.debug('Evaluate cv result (training set) Fold {}'.format(num_fold))\n",
    "    # Read cv result\n",
    "    filepath_fold_train = os.path.join(output_dir, f'cv_fold{num_fold}_training.csv')\n",
    "    pred_train_df = pd.read_csv(filepath_fold_train)\n",
    "    pred_train_df['actual'] = train.loc[pred_train_df['object_id'], TARGET].values\n",
    "    if REGRESSION:\n",
    "        if TARGET == 'target':\n",
    "            pred_train_df['pred'].clip(lower=0, upper=3, inplace=True)\n",
    "        else:\n",
    "            pred_train_df['pred'] = np.vectorize(soring_date2target)(pred_train_df['pred'])\n",
    "            pred_train_df['actual'] = np.vectorize(soring_date2target)(pred_train_df['actual'])\n",
    "    else:\n",
    "        pred_train_df['pred'] = predict(pred_train_df['0'], pred_train_df['1'],\n",
    "                                        pred_train_df['2'], pred_train_df['3'])\n",
    "    if not (REGRESSION and TARGET == 'target'):\n",
    "        print(confusion_matrix(pred_train_df['actual'], pred_train_df['pred'],\n",
    "                               labels=np.sort(train['target'].unique())))\n",
    "    loss = rmse(pred_train_df['actual'], pred_train_df['pred'])\n",
    "#     score = qwk(pred_train_df['actual'], pred_train_df['pred'])\n",
    "    logger.debug('Loss: {}'.format(loss))\n",
    "#     logger.debug('Score: {}'.format(score))\n",
    "    metrics['train_losses'].append(loss)\n",
    "#     metrics['train_scores'].append(score)\n",
    "    pred_train_dfs.append(pred_train_df)\n",
    "\n",
    "metrics['train_losses_avg'] = np.mean(metrics['train_losses'])\n",
    "metrics['train_losses_std'] = np.std(metrics['train_losses'])\n",
    "# metrics['train_scores_avg'] = np.mean(metrics['train_scores'])\n",
    "# metrics['train_scores_std'] = np.std(metrics['train_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002bff09b09998d0be65</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00309fb1ef05416f9c1f</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003a1562e97f79ba96dc</th>\n",
       "      <td>2.40000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004890880e8e7431147b</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00718c32602425f504c1</th>\n",
       "      <td>1.80000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffa3259fff8e6f3818a1</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd4d361756587883e48</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd794b7b311b7b7fd92</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe49bba69d06446de7e</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe77db10be3400bed53</th>\n",
       "      <td>1.60000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pred  actual\n",
       "object_id                           \n",
       "002bff09b09998d0be65 1.60000       1\n",
       "00309fb1ef05416f9c1f 1.60000       3\n",
       "003a1562e97f79ba96dc 2.40000       3\n",
       "004890880e8e7431147b 1.60000       2\n",
       "00718c32602425f504c1 1.80000       3\n",
       "...                      ...     ...\n",
       "ffa3259fff8e6f3818a1 1.60000       3\n",
       "ffd4d361756587883e48 1.60000       1\n",
       "ffd794b7b311b7b7fd92 1.60000       2\n",
       "ffe49bba69d06446de7e 1.60000       3\n",
       "ffe77db10be3400bed53 1.60000       1\n",
       "\n",
       "[3937 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_train = pd.concat(pred_train_dfs).groupby('object_id').sum()\n",
    "pred_train = pred_train / N_SPLITS\n",
    "if not REGRESSION:\n",
    "    pred_train['pred'] = predict(pred_train['0'], pred_train['1'], pred_train['2'], pred_train['3'])\n",
    "pred_train['actual'] = train.loc[pred_train.index, TARGET].values\n",
    "if REGRESSION and TARGET == 'sorting_date':\n",
    "    pred_train['actual'] = np.vectorize(soring_date2target)(pred_train['actual'])\n",
    "# for c in ('pred', 'actual'):\n",
    "#     pred_train[c] = pred_train[c].astype('int')\n",
    "pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:03:14,315 - __main__ - INFO - Training loss: 1.1807661870233146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  64  410    1    0]\n",
      " [  35  853    8    0]\n",
      " [   1 1481   29    0]\n",
      " [   1  828  226    0]]\n"
     ]
    }
   ],
   "source": [
    "if not (REGRESSION and TARGET == 'target'):\n",
    "    print(confusion_matrix(pred_train['actual'], pred_train['pred'], labels=np.sort(train['target'].unique())))\n",
    "loss = rmse(pred_train['actual'], pred_train['pred'])\n",
    "# score = qwk(pred_train['actual'], pred_train['pred'])\n",
    "metrics['train_loss'] = loss\n",
    "# metrics['train_score'] = score\n",
    "logger.info('Training loss: {}'.format(loss))\n",
    "# logger.info('Training score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:03:18,394 - __main__ - DEBUG - Write cv result to ..\\scripts\\..\\experiments\\exp007\\prediction_train.csv\n"
     ]
    }
   ],
   "source": [
    "pred_train.to_csv(os.path.join(output_dir, 'prediction_train.csv'))\n",
    "logger.debug('Write cv result to {}'.format(os.path.join(output_dir, 'prediction_train.csv')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:04:06,190 - __main__ - DEBUG - Evaluate cv result (validation set) Fold 1\n",
      "2021-07-17 23:04:06,210 - __main__ - DEBUG - Loss: 0.9955988469207677\n",
      "2021-07-17 23:04:06,211 - __main__ - DEBUG - Evaluate cv result (validation set) Fold 2\n",
      "2021-07-17 23:04:06,227 - __main__ - DEBUG - Loss: 0.957202754593854\n",
      "2021-07-17 23:04:06,228 - __main__ - DEBUG - Evaluate cv result (validation set) Fold 3\n",
      "2021-07-17 23:04:06,244 - __main__ - DEBUG - Loss: 0.969797055632736\n",
      "2021-07-17 23:04:06,245 - __main__ - DEBUG - Evaluate cv result (validation set) Fold 4\n",
      "2021-07-17 23:04:06,261 - __main__ - DEBUG - Loss: 0.9897564520602553\n",
      "2021-07-17 23:04:06,263 - __main__ - DEBUG - Evaluate cv result (validation set) Fold 5\n",
      "2021-07-17 23:04:06,278 - __main__ - DEBUG - Loss: 0.9459405630355134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   6  98   2]\n",
      " [  0  10 170   2]\n",
      " [  0   3 290  12]\n",
      " [  0   2 173  29]]\n",
      "[[  0  12  78   1]\n",
      " [  0   4 174   3]\n",
      " [  0   1 289   6]\n",
      " [  0   0 185  23]]\n",
      "[[  0  15  82   0]\n",
      " [  0  11 171   7]\n",
      " [  0   8 281  21]\n",
      " [  0   1 168  25]]\n",
      "[[  0   6  87   0]\n",
      " [  0   3 177   3]\n",
      " [  0   1 258  15]\n",
      " [  0   0 210  25]]\n",
      "[[  0   9  79   0]\n",
      " [  0   4 152   5]\n",
      " [  0   1 311  14]\n",
      " [  0   2 186  26]]\n"
     ]
    }
   ],
   "source": [
    "pred_valid_dfs = []\n",
    "for i in range(N_SPLITS):\n",
    "    num_fold = i + 1\n",
    "    logger.debug('Evaluate cv result (validation set) Fold {}'.format(num_fold))\n",
    "    # Read cv result\n",
    "    filepath_fold_valid = os.path.join(output_dir, f'cv_fold{num_fold}_validation.csv')\n",
    "    pred_valid_df = pd.read_csv(filepath_fold_valid)\n",
    "    pred_valid_df['actual'] = train.loc[pred_valid_df['object_id'], TARGET].values\n",
    "    if REGRESSION:\n",
    "        if TARGET == 'target':\n",
    "            pred_valid_df['pred'].clip(lower=0, upper=3, inplace=True)\n",
    "        else:\n",
    "            pred_valid_df['pred'] = np.vectorize(soring_date2target)(pred_valid_df['pred'])\n",
    "            pred_valid_df['actual'] = np.vectorize(soring_date2target)(pred_valid_df['actual'])\n",
    "    else:\n",
    "        pred_valid_df['pred'] = predict(pred_valid_df['0'], pred_valid_df['1'],\n",
    "                                        pred_valid_df['2'], pred_valid_df['3'])        \n",
    "    \n",
    "    if not (REGRESSION and TARGET == 'target'):\n",
    "        print(confusion_matrix(pred_valid_df['actual'], pred_valid_df['pred'],\n",
    "                               labels=np.sort(train['target'].unique())))\n",
    "    loss = rmse(pred_valid_df['actual'], pred_valid_df['pred'])\n",
    "#     score = qwk(pred_valid_df['actual'], pred_valid_df['pred'])\n",
    "    logger.debug('Loss: {}'.format(loss))\n",
    "#     logger.debug('Score: {}'.format(score))\n",
    "    metrics['valid_losses'].append(loss)\n",
    "#     metrics['valid_scores'].append(score)\n",
    "    pred_valid_dfs.append(pred_valid_df)\n",
    "    \n",
    "metrics['valid_losses_avg'] = np.mean(metrics['valid_losses'])\n",
    "metrics['valid_losses_std'] = np.std(metrics['valid_losses'])\n",
    "# metrics['valid_scores_avg'] = np.mean(metrics['valid_scores'])\n",
    "# metrics['valid_scores_std'] = np.std(metrics['valid_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>002bff09b09998d0be65</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00309fb1ef05416f9c1f</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003a1562e97f79ba96dc</th>\n",
       "      <td>0.60000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004890880e8e7431147b</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00718c32602425f504c1</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffa3259fff8e6f3818a1</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd4d361756587883e48</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd794b7b311b7b7fd92</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe49bba69d06446de7e</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe77db10be3400bed53</th>\n",
       "      <td>0.40000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pred  actual\n",
       "object_id                           \n",
       "002bff09b09998d0be65 0.40000       1\n",
       "00309fb1ef05416f9c1f 0.40000       3\n",
       "003a1562e97f79ba96dc 0.60000       3\n",
       "004890880e8e7431147b 0.40000       2\n",
       "00718c32602425f504c1 0.40000       3\n",
       "...                      ...     ...\n",
       "ffa3259fff8e6f3818a1 0.40000       3\n",
       "ffd4d361756587883e48 0.40000       1\n",
       "ffd794b7b311b7b7fd92 0.40000       2\n",
       "ffe49bba69d06446de7e 0.40000       3\n",
       "ffe77db10be3400bed53 0.40000       1\n",
       "\n",
       "[3937 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_valid = pd.concat(pred_valid_dfs).groupby('object_id').sum()\n",
    "pred_valid = pred_valid / N_SPLITS\n",
    "if not REGRESSION:\n",
    "    pred_valid['pred'] = predict(pred_valid['0'], pred_valid['1'], pred_valid['2'], pred_valid['3'])\n",
    "pred_valid['actual'] = train.loc[pred_valid.index, TARGET].values\n",
    "if REGRESSION and TARGET == 'sorting_date':\n",
    "    pred_valid['actual'] = np.vectorize(soring_date2target)(pred_valid['actual'])\n",
    "# for c in ('pred', 'actual'):\n",
    "#     pred_valid[c] = pred_valid[c].astype('int')\n",
    "pred_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not REGRESSION:\n",
    "    print(confusion_matrix(pred_valid['actual'], pred_valid['pred'], labels=np.sort(train['target'].unique())))\n",
    "loss = rmse(pred_valid['actual'], pred_valid['pred'])\n",
    "# score = qwk(pred_valid['actual'], pred_valid['pred'])\n",
    "metrics['valid_loss'] = loss\n",
    "# metrics['valid_score'] = score\n",
    "logger.info('Validatino loss: {}'.format(loss))\n",
    "# logger.info('Validatino score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:05:07,280 - __main__ - DEBUG - Write cv result to ..\\scripts\\..\\experiments\\exp007\\prediction_valid.csv\n"
     ]
    }
   ],
   "source": [
    "pred_valid.to_csv(os.path.join(output_dir, 'prediction_valid.csv'))\n",
    "logger.debug('Write cv result to {}'.format(os.path.join(output_dir, 'prediction_valid.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:05:08,115 - __main__ - DEBUG - Write metrics to ..\\scripts\\..\\experiments\\exp007\\metrics.json\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(output_dir, 'metrics.json'), 'w') as f:\n",
    "    json.dump(dict(metrics), f)\n",
    "logger.debug('Write metrics to {}'.format(os.path.join(output_dir, 'metrics.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_dfs = []\n",
    "for i in range(N_SPLITS):\n",
    "    num_fold = i + 1\n",
    "    # Read cv result\n",
    "    filepath_fold_test = os.path.join(output_dir, f'cv_fold{num_fold}_test.csv')\n",
    "    pred_test_df = pd.read_csv(filepath_fold_test)\n",
    "    pred_test_dfs.append(pred_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0009e50b94be36ccad39</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bd5e82eb22f199f44</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0015f44de1854f617516</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00388a678879ba1efa27</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>005e1e7c6496902d23f3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbe65ad399b632dcbd0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd7b2d646c0320c311a</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffdb93ede17d4501e530</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe111402004b0ed46b4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fffdb3c248a7dcd3cccf</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5919 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      pred\n",
       "object_id                 \n",
       "0009e50b94be36ccad39     2\n",
       "000bd5e82eb22f199f44     2\n",
       "0015f44de1854f617516     2\n",
       "00388a678879ba1efa27     2\n",
       "005e1e7c6496902d23f3     2\n",
       "...                    ...\n",
       "ffbe65ad399b632dcbd0     3\n",
       "ffd7b2d646c0320c311a     2\n",
       "ffdb93ede17d4501e530     2\n",
       "ffe111402004b0ed46b4     2\n",
       "fffdb3c248a7dcd3cccf     2\n",
       "\n",
       "[5919 rows x 1 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = pd.concat(pred_test_dfs).groupby('object_id').sum()\n",
    "pred_test = pred_test / N_SPLITS\n",
    "if REGRESSION:\n",
    "    if TARGET == 'target':\n",
    "        pred_test['pred'].clip(lower=0, upper=3, inplace=True)\n",
    "    else:\n",
    "        pred_test['pred'] = np.vectorize(soring_date2target)(pred_test['pred'])\n",
    "else:\n",
    "    pred_test['pred'] = predict(pred_test['0'], pred_test['1'], pred_test['2'], pred_test['3'])\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5919 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0          2\n",
       "1          2\n",
       "2          2\n",
       "3          2\n",
       "4          2\n",
       "...      ...\n",
       "5914       3\n",
       "5915       2\n",
       "5916       2\n",
       "5917       2\n",
       "5918       2\n",
       "\n",
       "[5919 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['target'] = pred_test.loc[test['object_id'], 'pred'].values\n",
    "test = test[['target']]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5919 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target\n",
       "0          3\n",
       "1          1\n",
       "2          3\n",
       "3          3\n",
       "4          0\n",
       "...      ...\n",
       "5914       2\n",
       "5915       1\n",
       "5916       1\n",
       "5917       3\n",
       "5918       3\n",
       "\n",
       "[5919 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:05:37,830 - __main__ - DEBUG - Write submission to ..\\scripts\\..\\experiments\\exp007\\007_submission.csv\n"
     ]
    }
   ],
   "source": [
    "test.to_csv(os.path.join(output_dir, f'{str(EXP_NO).zfill(3)}_submission.csv'), index=False)\n",
    "logger.debug('Write submission to {}'.format(os.path.join(output_dir, f'{str(EXP_NO).zfill(3)}_submission.csv')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:05:39,406 - __main__ - DEBUG - Write figure to ..\\scripts\\..\\experiments\\exp007\\prediction.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAARk0lEQVR4nO3df+xd9V3H8eeLFoGN4SB8wdqCw1kXCzoWmg7FGB1G6q/RTDE1bjSKVhHNlugcGOPP1GDURZmDpHGTVreRuh9SiUyxDpdNNlYmEwoSqkxoqLQw54oaHPXtH/eDu5bb7+e26723336fj+Tknvu+53Pu+5sb+uKcz7nnpqqQJGk+J826AUnS8c+wkCR1GRaSpC7DQpLUZVhIkrqWzrqBSVm7dm19+MMfnnUbkrTQZFTxhD2yePrpp2fdgiSdME7YsJAkHTuGhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldJ+ztPrQ4PP7r3zjrFhaF83/5gVm3oBnzyEKS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldEw2LJJ9N8kCS+5PsbLWzktyV5NH2eObQ9jck2Z3kkSRXDNUvafvZneSmJJlk35Kk/28aRxbfUVUXV9Xq9vx6YEdVrQR2tOckWQWsBy4E1gI3J1nSxtwCbARWtmXtFPqWJDWzOA11JbClrW8B1g3Vb6uq56rqMWA3sCbJMuCMqrqnqgrYOjRGkjQFkw6LAv4qyX1JNrbauVW1F6A9ntPqy4EnhsbuabXlbf3QuiRpSib9S3mXVdWTSc4B7kryj/NsO2oeouapv3gHg0DaCHD++ecfaa+SpMOY6JFFVT3ZHvcBHwLWAE+1U0u0x31t8z3AeUPDVwBPtvqKEfVR77e5qlZX1eq5ublj+adI0qI2sbBI8tIkL3thHfgu4EFgO7ChbbYBuL2tbwfWJzklyQUMJrLvbaeqDiS5tF0FdfXQGEnSFEzyNNS5wIfaVa5LgfdW1YeTfArYluQa4HHgKoCq2pVkG/AQ8DxwXVUdbPu6FrgVOA24sy2SpCmZWFhU1T8Drx5Rfwa4/DBjNgGbRtR3Ahcd6x4lSePxG9ySpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeqaeFgkWZLk75Pc0Z6fleSuJI+2xzOHtr0hye4kjyS5Yqh+SZIH2ms3Jcmk+5Ykfck0jizeDDw89Px6YEdVrQR2tOckWQWsBy4E1gI3J1nSxtwCbARWtmXtFPqWJDUTDYskK4DvBf5wqHwlsKWtbwHWDdVvq6rnquoxYDewJsky4IyquqeqCtg6NEaSNAWTPrL4PeAXgP8Zqp1bVXsB2uM5rb4ceGJouz2ttrytH1p/kSQbk+xMsnP//v3H5A+QJE0wLJJ8H7Cvqu4bd8iIWs1Tf3GxanNVra6q1XNzc2O+rSSpZ+kE930Z8Pok3wOcCpyR5E+Ap5Isq6q97RTTvrb9HuC8ofErgCdbfcWIuiRpSiZ2ZFFVN1TViqp6BYOJ67+pqjcC24ENbbMNwO1tfTuwPskpSS5gMJF9bztVdSDJpe0qqKuHxkiSpmCSRxaHcyOwLck1wOPAVQBVtSvJNuAh4Hnguqo62MZcC9wKnAbc2RZJ0pRMJSyq6m7g7rb+DHD5YbbbBGwaUd8JXDS5DiVJ8/Eb3JKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktQ1Vlgk2TFOTZJ0Ylo634tJTgVeApyd5Ewg7aUzgK+ecG+SpOPEvGEB/CTwFgbBcB9fCosvAO+cXFuSpOPJvKehqur3q+oC4Oer6mur6oK2vLqq/mC+sUlOTXJvks8k2ZXk11r9rCR3JXm0PZ45NOaGJLuTPJLkiqH6JUkeaK/dlCSj3lOSNBm9IwsAquodSb4FeMXwmKraOs+w54DXVdWzSU4GPpbkTuANwI6qujHJ9cD1wNuSrALWAxcyOJL56yRfX1UHgVuAjcAngL8A1gJ3HtmfKkk6WmOFRZI/Bl4J3A8cbOUCDhsWVVXAs+3pyW0p4Erg21t9C3A38LZWv62qngMeS7IbWJPks8AZVXVP62UrsA7DQpKmZqywAFYDq1oAjC3JEgZzHV8HvLOqPpnk3KraC1BVe5Oc0zZfzuDI4QV7Wu2Lbf3Q+qj328jgCITzzz//SFqVJM1j3O9ZPAh81ZHuvKoOVtXFwAoGRwkXzbP5qHmImqc+6v02V9Xqqlo9Nzd3pO1Kkg5j3COLs4GHktzLYC4CgKp6/TiDq+rzSe5mMNfwVJJl7ahiGbCvbbYHOG9o2ArgyVZfMaIuSZqSccPiV490x0nmgC+2oDgN+E7gt4DtwAbgxvZ4exuyHXhvkrczmOBeCdxbVQeTHEhyKfBJ4GrgHUfajyTp6I17NdTfHsW+lwFb2rzFScC2qrojyT3AtiTXAI8DV7X32JVkG/AQ8DxwXbsSCuBa4FbgNAYT205uS9IUjXs11AG+NE/wFQyubPqPqjrjcGOq6h+A14yoPwNcfpgxm4BNI+o7gfnmOyRJEzTukcXLhp8nWQesmURDkqTjz1Hddbaq/gx43bFtRZJ0vBr3NNQbhp6exOB7F0f0nQtJ0sI17tVQ3z+0/jzwWQbfuJYkLQLjzln86KQbkSQdv8b98aMVST6UZF+Sp5J8IMmK/khJ0olg3AnuP2LwpbmvZnBfpj9vNUnSIjBuWMxV1R9V1fNtuRXw5kuStEiMGxZPJ3ljkiVteSPwzCQbkyQdP8YNix8Dfgj4V2Av8IOAk96StEiMe+nsbwAbqurfYPDTqMDvMAgRSdIJbtwji296ISgAqupzjLjvkyTpxDRuWJyU5MwXnrQji3GPSiRJC9y4/+D/LvB3Sd7P4DYfP8SIu8NKkk5M436De2uSnQxuHhjgDVX10EQ7kyQdN8Y+ldTCwYCQpEXoqG5RLklaXAwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKlrYmGR5LwkH0nycJJdSd7c6mcluSvJo+1x+EeVbkiyO8kjSa4Yql+S5IH22k1JMqm+JUkvNskji+eBn6uqbwAuBa5Lsgq4HthRVSuBHe057bX1wIXAWuDmJEvavm4BNgIr27J2gn1Lkg4xsbCoqr1V9em2fgB4GFgOXAlsaZttAda19SuB26rquap6DNgNrEmyDDijqu6pqgK2Do2RJE3BVOYskrwCeA3wSeDcqtoLg0ABzmmbLQeeGBq2p9WWt/VD66PeZ2OSnUl27t+//5j+DZK0mE08LJKcDnwAeEtVfWG+TUfUap76i4tVm6tqdVWtnpubO/JmJUkjTTQskpzMICjeU1UfbOWn2qkl2uO+Vt8DnDc0fAXwZKuvGFGXJE3JJK+GCvAu4OGqevvQS9uBDW19A3D7UH19klOSXMBgIvvedqrqQJJL2z6vHhojSZqCpRPc92XAm4AHktzfar8I3AhsS3IN8DhwFUBV7UqyDXiIwZVU11XVwTbuWuBW4DTgzrZIkqZkYmFRVR9j9HwDwOWHGbMJ2DSivhO46Nh1J0k6En6DW5LUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXRMLiyTvTrIvyYNDtbOS3JXk0fZ45tBrNyTZneSRJFcM1S9J8kB77aYkmVTPkqTRJnlkcSuw9pDa9cCOqloJ7GjPSbIKWA9c2MbcnGRJG3MLsBFY2ZZD9ylJmrCJhUVVfRT43CHlK4EtbX0LsG6ofltVPVdVjwG7gTVJlgFnVNU9VVXA1qExkqQpmfacxblVtRegPZ7T6suBJ4a229Nqy9v6ofWRkmxMsjPJzv379x/TxiVpMTteJrhHzUPUPPWRqmpzVa2uqtVzc3PHrDlJWuymHRZPtVNLtMd9rb4HOG9ouxXAk62+YkRdkjRF0w6L7cCGtr4BuH2ovj7JKUkuYDCRfW87VXUgyaXtKqirh8ZIkqZk6aR2nOR9wLcDZyfZA/wKcCOwLck1wOPAVQBVtSvJNuAh4Hnguqo62HZ1LYMrq04D7myLJGmKJhYWVfXDh3np8sNsvwnYNKK+E7joGLYmSTpCx8sEtyTpOGZYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSepaOusGJC1el73jslm3cML7+M9+/JjsxyMLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC4vnQUueevWWbdwwrvvt6+edQuSvgweWUiSuhZMWCRZm+SRJLuTXD/rfiRpMVkQYZFkCfBO4LuBVcAPJ1k1264kafFYEGEBrAF2V9U/V9V/A7cBV864J0laNFJVs+6hK8kPAmur6sfb8zcBr62qnzlku43Axvb0VcAjU210us4Gnp51EzoqfnYL24n++T1dVWsPLS6Uq6EyovailKuqzcDmybcze0l2VtXqWfehI+dnt7At1s9voZyG2gOcN/R8BfDkjHqRpEVnoYTFp4CVSS5I8hXAemD7jHuSpEVjQZyGqqrnk/wM8JfAEuDdVbVrxm3N2qI43XaC8rNb2Bbl57cgJrglSbO1UE5DSZJmyLCQJHUZFgtIkncn2ZfkwVn3oiOX5LwkH0nycJJdSd486540niSnJrk3yWfaZ/drs+5p2pyzWECSfBvwLLC1qi6adT86MkmWAcuq6tNJXgbcB6yrqodm3Jo6kgR4aVU9m+Rk4GPAm6vqEzNubWo8slhAquqjwOdm3YeOTlXtrapPt/UDwMPA8tl2pXHUwLPt6cltWVT/p21YSDOQ5BXAa4BPzrgVjSnJkiT3A/uAu6pqUX12hoU0ZUlOBz4AvKWqvjDrfjSeqjpYVRczuIPEmiSL6lSwYSFNUTvf/QHgPVX1wVn3oyNXVZ8H7gZedLO9E5lhIU1JmyR9F/BwVb191v1ofEnmkry8rZ8GfCfwjzNtasoMiwUkyfuAe4BXJdmT5JpZ96QjchnwJuB1Se5vy/fMuimNZRnwkST/wOBedXdV1R0z7mmqvHRWktTlkYUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC+koJHl5kp+ewvusS7Jq0u8j9RgW0tF5OTB2WGTgaP57WwcYFpo5v2chHYUktwFXAo8AHwG+CTiTwd1If6mqbm83C7yzvf7NDP7hvxr4EeAJ4Gngvqr6nSSvBN4JzAH/CfwEcBZwB/DvbfmBqvqnKf2J0v+zdNYNSAvU9cBFVXVxkqXAS6rqC0nOBj6RZHvb7lXAj1bVTydZDfwAg7vNLgU+zeA3LQA2Az9VVY8meS1wc1W9ru3njqp6/zT/OOlQhoX05Qvwm+3Hqf6HwW9UnNte+5ehH8j5VuD2qvovgCR/3h5PB74F+NPB7aMAOGVKvUtjMSykL9+PMDh9dElVfTHJZ4FT22v/MbRdDh3YnAR8vt3+WjouOcEtHZ0DwMva+lcC+1pQfAfwNYcZ8zHg+9vvOZ8OfC9A+02Lx5JcBf83Gf7qEe8jzYxhIR2FqnoG+HiSB4GLgdVJdjI4yhh56+qq+hSwHfgM8EFgJ4OJa9q4a5J8BtjFYPIc4DbgrUn+vk2CSzPh1VDSFCU5vaqeTfIS4KPAxhd+l1s6njlnIU3X5vYlu1OBLQaFFgqPLCRJXc5ZSJK6DAtJUpdhIUnqMiwkSV2GhSSp638B40yyHKvX2DwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "if not (REGRESSION and TARGET == 'target'):\n",
    "    sns.countplot(data=test, x='target')\n",
    "else:\n",
    "    sns.histplot(data=test, x='target')\n",
    "sns.despine()\n",
    "fig.savefig(os.path.join(output_dir, 'prediction.png'))\n",
    "logger.debug('Write figure to {}'.format(os.path.join(output_dir, 'prediction.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 23:05:42,802 - __main__ - DEBUG - Complete (16857.193 seconds passed)\n"
     ]
    }
   ],
   "source": [
    "logger.debug('Complete ({:.3f} seconds passed)'.format(time.time() - SINCE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
